The Rust-Stainless tool is developed as an open source software
project.\footnote{\url{https://github.com/epfl-lara/rust-stainless/}} It was
created by Georg Schmid to explore a new frontend to Stainless for the Rust
language. Upon completion of this thesis project, the tool is implemented in
approximately 12K lines of Rust code. Most features described here are available
on the \lstinline!master! branch, except for the mutability translation that
lives on the \lstinline!mutable-cells!
branch.\footnote{\url{https://github.com/epfl-lara/rust-stainless/pull/164}}

Before presenting the tool's design and details about its implementation, the
next section provides some background on the Rust compiler needed to understand
the workings of our tool. The subsequent sections establish what language
features the tool was already capable of extracting before this thesis project
and what new features have been introduced. Finally, limitations of the current
approach and implementation are discussed.


\section{Background}

\subsection{Rust Compiler}

To make the translation of Rust code manageable and minimise the amount of
busy-work the tool needs to do, it heavily relies on the Rust compiler
\cite{rustc-guide}, \passthrough{\lstinline!rustc!}. The compiler takes Rust
source code as input and produces an executable binary. This process involves
multiple phases that each transform or \emph{lower} the high-level input source
into a more low-level representation. The following paragraphs give  a brief
overview of the compilation process while the leftmost column of
\autoref{fig:flowchart} illustrates the different phases.

The Rust compiler always operates on a single crate. That is, each crate is
compiled separately and maybe linked to other crates only after compilation.
This means that the \emph{intermediate representations} described afterwards are
only available for items of the current crate. The exception is for some
metadata of public items like function signatures that need to be accessible
across crates.

The first two compilation phases are concerned with transforming the input text
source into a token stream -- lexing -- and then into an \emph{abstract syntax
tree (AST)} -- parsing. First syntactical validations, name resolutions and
macro expansion are performed on the AST. While the AST is already a
representation of the program, it still maps directly to the source code and can
be seen as a data structure representation of the source text.

The first intermediate representation (IR) constructed from the AST is
the \emph{high-level IR (HIR)}. This is the first IR in that it contains
much less high-level features, because many have been desugared. The HIR
is used to type check the program. In that process an even lower-level
IR is created, the \emph{typed HIR (THIR)}. Still in the form of a tree,
this IR contains the full explicit type information.

The THIR is subsequently used to construct the \emph{mid-level IR (MIR)}
that has the form of a \emph{control-flow graph (CFG)}. Such a graph is
a diagram that consists of \emph{basic blocks} of code and arrows
between them that represent all the possible paths the control flow can
take. The MIR still has generic types but because it is a CFG it is much
more convenient for performing things like liveness analysis,
optimisations, and most importantly, the borrow check of the program.

The last phase of compilation is the \emph{code generation} phase. In
that step the generic code is \emph{monomorphised} i.e.~copied and
output for each type it is instantiated with. Then a special IR for the
compiler backend framework \emph{LLVM} \cite{llvm} is generated. LLVM
will perform much more performance optimisations and finally generate
the assembly code.

\section{System Overview}

\subsection{Design}

The Rust-Stainless verification system consists of multiple components,
most of which are implemented as their own Rust crate. Each component
modularly fulfils a step in the overarching goal of taking Rust code,
transforming it for Stainless and getting a verification result back. In
that sense, Rust-Stainless is an alternative frontend to Stainless for
Rust, much like the Rust compiler is an alternative frontend to LLVM.

Rust-Stainless itself has a frontend and a backend.
\lstinline!stainless_frontend! is the frontend crate of the tool and contains
two executables with which the tool is started and which deal with command line
arguments. The subcommand for the Cargo build tool \passthrough{\lstinline!cargo
stainless!} is the most common way of running Rust-Stainless. Internally, it
calls the second stand-alone binary \lstinline!rustc_to_stainless! which runs
the actual frontend of the tool.

\begin{figure}
  \begin{center}
  \input{img/flowchart}
  \caption{
    The Rust-Stainless pipeline depicted with all intermediate representations
    of the user program. The left column on its own shows the normal compilation
    pipeline of Rust's compiler. The grey parts are not executed in Rust-Stainless.
  }
  \label{fig:flowchart}
  \end{center}
\end{figure}

The programmer also sees another interface of Rust-Stainless, its
library \lstinline!libstainless!. The library needs to be
imported as \passthrough{\lstinline!extern crate stainless;!} in all
code that is to be verified. It provides the user-facing parts of
Rust-Stainless like the specification macros and some built-in Stainless
types useful for specification: an immutable generic set and map.

The main work of the translation is performed by the
\passthrough{\lstinline!stainless\_extraction!} crate. The frontend
calls the method \passthrough{\lstinline!extract\_crate!} which
retrieves the HIR from the compiler and translates it to Stainless AST
with the help of another crate,
\passthrough{\lstinline!stainless\_data!}. The latter contains the
auto-generated Rust definitions of the Stainless ASTs as well as code to
serialise them to a binary format.

Finally, \passthrough{\lstinline!stainless\_backend!} is responsible for
spawning and interacting with a JVM subprocess of the actual Stainless
executable. The executable consist of the normal Stainless verification
pipeline but with a custom entry-point called
\passthrough{\lstinline!Noxt-Frontend!}. ``Noxt'' stands for \emph{no
extraction} which means it takes as input serialised trees instead of
extracting trees from the Scala compiler output.

\subsection{Pipeline}
\label{sec:pipeline}

Having introduced the system's components, the next section traces the path of
an exemplary program through the Rust-Stainless pipeline in more detail. The
path can also be followed on  \autoref{fig:flowchart}. Gaining insight into the
pipeline will also increase understanding of the design decisions made.

\noindent\begin{minipage}[b]{.45\textwidth}
\begin{lstlisting}[
  language=Rust,
  caption={Rust program with a post-condition.},
  label={lst:example},
]
extern crate stainless;
use stainless::*;

struct A(i32);

#[post(ret.0 >= 0)]
fn f(a: A) -> A {
  A(a.0 * a.0)
}
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}[b]{.52\textwidth}
\begin{lstlisting}[
  language=Rust,
  caption={Desugared post-condition.},
  label={lst:example2}
]
fn f(a: A) -> A {
  #[clippy::stainless::post]
  |a: A, ret: A| -> bool {ret.0 >= 0};
  A(a.0 * a.0)
}
\end{lstlisting}
\end{minipage}

In \autoref{lst:example}, the Stainless library is added as an external crate
and then imported such that the post-condition specification attribute
\passthrough{\lstinline!\#[post()]!} is available. The attribute is implemented
as a procedural macro\footnote{Procedural macros invoke user-provided code at
compilation-time and hence, allow for more complex transformations of the AST
inside a macro \cite[section ``Procedural Macros'']{rustref}.} and will be
expanded to a closure inside the function (\autoref{lst:example2}).

Rust-Stainless leverages the heavy lifting done by the Rust compiler. The
frontend invokes the compiler via the \passthrough{\lstinline!rustc\_driver!}
library and runs all the phases until all analyses are complete and pass,
otherwise the tool fails with the error given by
\passthrough{\lstinline!rustc!}. In particular, the compiler does the lexing,
parsing, macro expansion and IR construction. Secondly, the compiler type and
borrow checks the program. This way, we achieve our strong assumption from
\autoref{correctness-claim} because Rust-Stainless only continues if all checks
pass.

Once analysis is complete, the extraction module is invoked on the HIR.
As Rust's compile model prescribes that the HIR is only ever constructed
for the current crate, our toll also only translates the current crate.
We further examine that limitation of our implementation in \autoref{impl-limitations}.

The extraction traverses all the \emph{items} of the crate, that is top-level
functions, structs, enums, \passthrough{\lstinline!impl!} blocks and their
methods as well as traits. It directly constructs Stainless definitions for data
types. For function and method bodies, the extraction works on the THIR, which
is guaranteed to exist as the type check passed. The body of our example
function in THIR can be seen in \autoref{apx:thir-example}.

The HIR is very well suited for translation to Stainless AST because it is still
in the form of an AST but all the type information is explicit and implicit
features like method calls and dereferences have been resolved or desugared.
That way, the THIR is the representation that is the closest to Stainless AST
which makes translation simpler. The downside of working with the THIR instead
of the MIR is that lifetime resolution is performed on the MIR. Hence, in the
THIR there is no way of knowing the exact point where a binding or reference
ends its lifetime. This is a serious limitation if one needs the lifetimes in
the translation, for example for some other encoding of mutability as explored
in \autoref{impl-limitations}.


If all the THIR can be translated to Stainless AST without errors, i.e.~there
are no unsupported features in the program, the AST is serialised to the custom
binary format that is used by Stainless's caching mechanism. At this point, the
program consists of a list of functions, a list of ADTs and a list of classes
(\autoref{lst:stainless-trees}).

\begin{lstlisting}[
  language=Scala,
  label={lst:stainless-trees},
  caption={Extracted Stainless ADTs and functions, printed as code.}
]
sealed case class A(_0: MutCell[Int])
sealed case class MutCell[T @mutable]((value: T @mutable) @var)

@pure def f(a: A): A = {
  freshCopy(A(MutCell[Int](a._0.value * a._0.value)))
} ensuring {
  (ret: A) => ret._0.value >= 0
}
\end{lstlisting}

Either the user specified to export the AST in which case the binary format is
simply written to a file, or the Stainless backend is started. Rust-Stainless
spawns a subprocess with the \passthrough{\lstinline!Noxt-Frontend!} of
Stainless and communicates with it via standard input and output. The subprocess
reads the AST from a temporary file, performs some minor transformation and
passes it through the verification pipeline. In the end, it reports back the
results in JSON format such that Rust-Stainless can print them. In the case of
the example, Stainless tells us that there is a problem: the multiplication on
line 5 of \autoref{lst:stainless-trees} could overflow and therefore, the
post-condition does not hold.



\section{Extraction}

\subsection{Supported Rust Features}
\label{sec:supported-features}

\begin{lstlisting}[
  float,
  language=Rust,
  label={lst:existing},
  caption={Example of existing features in Rust-Stainless.}
]
pub fn i32_ops(x: i32, y: i32) {
  assert!(x + y == 2 * x);
  if x >= 0 && x < 1<<30 {
    assert!(x == (x + x) / 2);
  }
}
enum Maybe<T> {
  Nothing,
  Just { value: T }
}
fn get_or<T>(maybe: Maybe<T>, default: T) -> T {
  match maybe {
    Maybe::Nothing => default,
    Maybe::Just { value } => value,
  }
}
#[pre(x >= 0)]
#[pre(x < 10)]
#[post(ret >= 0)]
pub fn fact(x: i32) -> i32 {
  if x <= 0 { 1 }
  else { fact(x - 1) * x }
}
\end{lstlisting}

\subsubsection{Existing Features}

The initial fragment of the Rust language that the tool could extract and
translate underlay strict restrictions: all code needed to be functional,
immutable and the only allowed side-effect was \lstinline"panic!". References,
heap allocation and with it recursive data types were impossible.

Apart from that, a large part of the language was already supported, i.e.~most
of the control-flow syntax, top-level functions with bodies, integer and boolean
expressions, string literals, pattern matching, ADTs, including tuples (without
their pattern matching), and generics. Function specifications (specs), that is
pre- and postconditions, could be stated with the \lstinline!pre! and
\lstinline!post! attributes from the \lstinline!stainless! crate.

The argument of a spec is a regular Rust expression that must have no effect on
any variables of the function body. This posed a problem in the absence of
references because oftentimes, the expression would consume a function parameter
of moveable type multiple times which does not borrow check. As a work-around,
one could add multiple specs of the same kind to a function which is equivalent
to multiple \lstinline!&&!-concatenated expressions.

With all of the above, an example of supported and verified Rust code before
this thesis project is \autoref{lst:existing}.

\subsubsection{New Features}

This section gives an overview of all the language features that were added to
the extraction in the course of this thesis project except for the mutability
translation which has been introduced in \autoref{translation}. The features
described here are available on the \lstinline!master! branch of the project.

\paragraph{Syntactical and Notational Improvements}

Support was added for:

\begin{itemize}
\item
  \passthrough{\lstinline!else if!} expressions,
\item
  \passthrough{\lstinline!let!} bindings with a user-specified type
  annotation, \passthrough{\lstinline!let t: u16 = 1;!},
\item
  pattern matching on tuples,
\item
  accessing tuple struct fields by their numerical identifier,
  \passthrough{\lstinline!A(2, 3).0!},
\item
  usage of the \passthrough{\lstinline!return!} keyword at most points
  of a function (but not in \lstinline!if! conditions and guards),
\item
  \passthrough{\lstinline!usize!} and \passthrough{\lstinline!isize!}
  integer types that have the bit-length of a pointer on the targeted
  platform,
\item
  \emph{struct update syntax}, a short-hand notation for creating a
  struct from an existing one,
\begin{lstlisting}[language=Rust]
struct A { a: i32, b: bool, c: char }
let x: A = A { a: 123, b: true, c: 'c' };
let y: A = A { b: false, ..x }; // copies `x.b`, `x.c`
\end{lstlisting}

\item
  crate local modules and imports, which includes the ability of
  splitting up a crate into multiple files, and finally,
\item
  panics in expression locations like an arm of a pattern match.
\begin{lstlisting}[language=Rust]
match Option::Some(123) {
  Option::Some(x) => x,
  Option::None => panic!("no value"),
}
\end{lstlisting}

\end{itemize}

\paragraph{Immutable References and Heap Allocation}

It is now possible to immutably borrow places, pass immutable references as
values and allocate data on the heap with boxes. Although already presented in
\autoref{translation}, the feature is mentioned here because it exists
independently of the mutability translation.

The above enables recursive data types like the typical, functional linked-list.
Additionally, this eases the problem of borrow checking spec expressions because
expressions that only read data, like most specifications do, can now take a
reference instead of consuming the data.

\begin{lstlisting}[language=Rust, style=short]
pub enum List<T> {
  Nil,
  Cons(T, Box<List<T>>),
}
\end{lstlisting}

\paragraph{Measure Attribute}

Recursive proofs in Stainless often require the programmer to state the
induction variable with a \lstinline!decreases! call in Scala. This helps
Stainless infer the so called \emph{measure} of the proof, with which it checks
termination. The same feature was introduced in Rust as a new spec attribute
which enables verification of recursive functions, like \autoref{lst:measure}.

\begin{lstlisting}[
  language=Rust,
  caption={Measure attribute.},
  label={lst:measure}
]
#[measure(l)]
fn size<T>(l: &List<T>) -> u32 {
  match l {
    List::Nil => 0,
    List::Cons(_, tail) => 1 + size(tail),
  }
}
\end{lstlisting}

\paragraph{Stainless Library}

As explained above, the \lstinline!stainless! crate is exposed to the programmer
and contains helpers for specifying proofs and conditions. This is the
equivalent of the \lstinline!stainless! package in Scala. In addition to the
pre-, post- and measure attributes the \lstinline!libstainless! now offers an
immutable, infinite set \passthrough{\lstinline!stainless::Set<T>!} and map
\passthrough{\lstinline!stainless::Map<K, V>!} implementation, see
\autoref{lst:map-set}.

In extraction, both of these types are translated to Stainless's built-in
infinite set and map type. Hence, they are backed and well-understood by
Stainless which enables their proof utility. At runtime of the program, the
collections are backed by a runnable implementation that relies on the
\lstinline!im! crate. The Rust interface of the collections was designed so as
to resemble the \lstinline!std::collections::HashSet! and \lstinline!HashMap! as
closely as possible.

\begin{lstlisting}[
  float,
  language=Rust,
  caption={The interface of the Stainless collections in Rust.},
  label=lst:map-set
]
Set<T> {
  fn new() -> Self;
  fn singleton(t: T) -> Self;
  fn insert(&self, t: T) -> Self;
  fn contains(&self, t: &T) -> bool;
  fn union(self, other: Set<T>) -> Self;
  fn intersection(self, other: Set<T>) -> Self;
  fn difference(self, other: Set<T>) -> Self;
  fn is_subset(&self, other: &Set<T>) -> bool;
}
Map<K, V> {
  fn new() -> Self;
  fn get(&self, key: &K) -> Option<&V>;
  fn get_or<'a>(&'a self, key: &K, elze: &'a V);
  /// Panics if the key is not in the map.
  fn index(&self, key: &K) -> &V;
  fn contains_key(&self, key: &K) -> bool;
  fn insert(&self, key: K, val: V) -> Self;
  fn remove(&self, key: &K) -> Self;
}
\end{lstlisting}

Furthermore, the library provides a helper function
\passthrough{\lstinline!implies!} that let's one write the logical
implication $p \implies q \equiv \neg{p} \land q$ over boolean expressions.


\paragraph{External and Synthesised ADTs}

Internally, the \lstinline!Map<K, V>! of the Stainless crate relies on the
\lstinline!MutableMap! of Scala Stainless with values of type
\lstinline!Option[V]!. To perform that translation, the extraction needs to
create trees of the \lstinline!Option! type, even if the
\lstinline!std::option::Option! doesn't occur in the program. Therefore,
Rust-Stainless can now synthesise values and types for certain specific ADTs:
\lstinline!Option!, tuples and mutable cells as described in
\autoref{sec:translation}.

The frontend also supports extraction of crate-external ADTs like
\lstinline!std::result::Result!. That means, the programmer can use the standard
structures and they are correctly translated, provided that no methods of these
types are used. This is the one-crate-limitation, discussed in
\autoref{impl-limitations}.

\paragraph{Implementation Blocks, Traits and Laws}

The largest addition, other than mutability, of this project is support for
implementation blocks, methods, and traits with contracts, as introduced in
\autoref{laws-intro}. This includes solving some intricate problems. For
example, the Rust compiler automatically and implicitly resolves which trait
implementation to use for any given trait method call. If no suitable
implementation is in scope, it signals an error.  A similar mechanism can be
achieved in Scala by means of \emph{type classes}. The resolution of type class
methods and instances is done through the \emph{implicits mechanism} of regular
Scala. In Stainless however, this resolution has to be done manually. Therefore,
Rust-Stainless not only extracts type classes from Rust traits, but it also
infers which type class instance to call at each method call site.

Furthermore, our tool is capable of extracting laws and specifications of traits
and their implementations, including specification attributes on abstract
methods. Lastly, it can extract  trait bounds like \passthrough{\lstinline!T:
Equals!} from top-level functions, trait implementations, and regular
implementation blocks, and transform them to the Scala equivalent pattern of
\emph{evidence parameters}. More details on this tranlsation are found in
\autoref{type-class-extraction}.



\subsection{Implementation Details}

\subsubsection{Extraction Overview}
\label{sec:extraction-overview}

As we have seen in \autoref{sec:pipeline}, the big majority of the work
performed by Rust-Stainless happens in the extraction of the HIR to
Stainless AST. We can now take a more detailed look at the most
interesting phase of our tool. The phase is implemented in the
\passthrough{\lstinline!stainless\_extraction!} crate and the
entry-point is the function \passthrough{\lstinline!extract\_crate!},
which -- as discussed -- processes the single current crate for which
\passthrough{\lstinline!rustc!} provides the HIR.

Before dealing with the user code in the crate, the extraction needs to
register some specially treated items that we call \emph{standard
items.} These are Rust language features like panic, standard library
items like \passthrough{\lstinline!Box<T>!} and
\passthrough{\lstinline!Option<T>!}, but also all types and methods of
\passthrough{\lstinline!libstainless!} like
\passthrough{\lstinline!Set<T>!} and \passthrough{\lstinline!get\_or!}.
Extraction needs to know the identifiers (the
\passthrough{\lstinline!DefId!}s) of those items in order to recognise
them in user code and trigger their specialised extraction procedures.
Initially, we only know the \emph{paths} of the items to detect e.g.
\passthrough{\lstinline!stainless::Set::new!} but that does not suffice
because \passthrough{\lstinline!rustc!} does not have an API to query
items from other crates \emph{by path} at the time of writing. All the
lookups are done by \passthrough{\lstinline!DefId!}. Therefore, the
implementation has to enumerate all \passthrough{\lstinline!DefId!}s
from the \passthrough{\lstinline!std!} and
\passthrough{\lstinline!stainless!} crate, compare them by name to the
desired items and register them if needed. This approach is clearly a
brute-force work-around around the lack of by-path lookups in
\passthrough{\lstinline!rustc!} but as the number of crates to take into
consideration is fixed and low, the lookup time is constant and
extraction time is still low.

With standard item detection done, the tool can now turn to user code.
The main procedure of extraction enumerates all top-level
items\footnote{\url{https://doc.rust-lang.org/nightly/nightly-rustc/rustc_hir/hir/enum.ItemKind.html}}
of the crate like functions, structs, enums and traits. For enums and
structs, the phase directly proceeds and translates the HIR definition
to a Stainless ADT definition. Because enumeration order is undefined,
all the top-level methods of the extraction follow the same idea:
\passthrough{\lstinline!get\_or\_extract!}. That is, the first time an
item is visited, it is extracted and its definition is stored in state,
then on subsequent encounters the definition is simply retrieved.

For functions, the extraction distinguishes between external, abstract
and local functions but not between methods and functions because in the
HIR the two are the same (with the first parameter of methods being the
receiver). External and abstract functions are only extracted from the
HIR as they only have a signature. For local functions, we query the
body expression in THIR form from the compiler and extract it with the
\passthrough{\lstinline!expr!} module. The
\passthrough{\lstinline!extract\_expr!} method of that module takes a
\passthrough{\lstinline!thir::Expr!} and returns a
\passthrough{\lstinline!st::Expr!}, hence it is the entry-point of the
actual translation.

\subsubsection{Synthesis}

Multiple translations that Rust-Stainless performs rely on the ability
to synthesise expressions of certain ADT types that do not necessarily
occur in user code. For example for the Stainless map, we construct
options (\passthrough{\lstinline!Some(v)!}), in other locations mutable
cells and tuples e.g.~\passthrough{\lstinline!Tuple3(x, y, z)!}.
Moreover, the fields of these ADTs also need to be available:
\passthrough{\lstinline!tuple.\_0!} and
\passthrough{\lstinline!cell.value!}.

In implementing synthesis, we observe a primary benefit of the
\passthrough{\lstinline!get\_or\_extract!} pattern. For example, when
some translation needs the option type, it triggers its synthesis.
But all synthesis methods internally implement a
\passthrough{\lstinline!get\_or\_create!} logic, i.e.~if the option type
has already been either extracted from user code or synthesised by a
former synthesis call, it is simply reused and the demanded ADT
expression can be built with its identifier. That way, we only
synthesise ADT definitions on demand and we never run the risk of
extracting one definition of option and synthesising a second one. The
latter also shows why it is crucial to register and recognise standard
items.

\subsubsection{Trait to Type Class Translation}
\label{type-class-extraction}

As mentioned in \autoref{sec:supported-features}, Rust-Stainless extracts traits
and models them as type classes in Scala. This introduces a distinction between
regular \lstinline!impl! blocks for which it suffices to extract the methods as
top-level functions, and \passthrough{\lstinline!impl TraitX for TypeA!} blocks
that need to be extracted as type class implementations, i.e.~\emph{case
classes} or \emph{case objects}. Traits themselves are extracted as
\emph{abstract classes}, see \autoref{lst:clstranslation0}.

Internally, Rust represents \passthrough{\lstinline!impl TraitX for TypeA!}
blocks with a \emph{trait bound} on the block i.e.~\passthrough{\lstinline!Self:
TraitX!}, while Scala uses inheritance (\passthrough{\lstinline!extends!}).
Furthermore, Rust traits are implemented on the implicit \lstinline!Self! type
parameter, whereas Scala type classes always have at least one type parameter
representing the type for which the class is implemented. Fortunately, the Rust
compiler internally treats the \lstinline!Self! like a regular type parameter,
hence internally it is already in the Scala form.

\noindent\begin{minipage}[t]{.49\textwidth}
\begin{lstlisting}[
  language=Rust,
  showlines=true,
  caption={Examples of traits and implementations with and without trait bounds.},
  label={lst:clstranslation0}
]
trait Equals {
  fn equals(&self, x: &Self) -> bool;

  fn not_equals(&self, x: &Self)
    -> bool {
      !self.equals(x)
    }
}
trait Other<X, Y> { ... }

impl Equals for i32 { ... }


impl<T: Equals> Equals for List<T>
  { ... }

let list: List<i32> = List::Cons(
  123, Box::new(List::Nil)
);
list.equals(&List::Nil)
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}[t]{.49\textwidth}
\begin{lstlisting}[
  language=Scala,
  caption={
    Translation as type classes (\lstinline!abstract!) and implementations.
    Trait bounds are translated as evidence parameters.},
  label={lst:clstranslation}
]
abstract class Equals[Self] {
  def equals(self: T, x: T): Boolean

  def notEquals(
    self: T, x: T
  ): Boolean =
    !this.equals(x, y)
}
abstract class Other[Self, X, Y]
  { ... }
case object i32asEquals
  extends Equals[Int] { ... }

case class ListasEquals[T](
  ev0: Equals[T]
) extends Equals[List[T]] { ... }

val list = Cons(123, Nil())
ListasEquals[i32](i32asEquals)
  .equals(list, Nil())
\end{lstlisting}
\end{minipage}

As \autoref{lst:clstranslation} shows, the trait bounds on type parameters are
converted to evidence parameters in Scala, like \passthrough{\lstinline!ev0:
Equals[T]!}. Evidence parameters force the caller to prove that the instantiated
type satisfies the bound by providing an instance of the corresponding type
class. This is equivalent to Rust's compiler ensuring that
\passthrough{\lstinline!impl Equals for T!} is in scope. If an implementation
has no type parameter, it can be extracted as a ground case object.

If there are classes, it is also necessary to distinguish \emph{function calls}
from \emph{method calls}. This distinction is mostly achieved by adding flags
like \passthrough{\lstinline!abstract!} and
\passthrough{\lstinline!methodOf(i32asEquals)!} to methods. The challenge of
method calls is to resolve the receiver instance they are called on. For
example, \autoref{lst:clstranslation} shows a call to \lstinline!this.equals!
inside the type class. In Rust, the call is on the first parameter of the
function which is also the receiver. This is implicitly resolved by the
compiler. In Stainless however, the call needs to happen on the type class
instance and because our type class instances are only created in the
extraction, the tool also has to resolve the receivers itself.

Instance resolution takes a triple of type class identifier, receiver type and
type parameters, as well as the current surrounding class to resolve the
receiver instance. For example, inside a type class, the \lstinline!this!
instance is accessible, inside classes with evidence parameters, the evidence
instances are available (e.g. \lstinline!ev0.eq(x, y)! in
\lstinline!ListasEquals[T]!) and ground case objects are always in scope. As a
last resort, instance resolution recursively checks whether it can create a new
type class instance by providing it the required evidence arguments. This
happens for example for the call on line 20 of \autoref{lst:clstranslation0}. It
gets translated to a new instance of \lstinline!ListasEquals! that is created
with the ground object \lstinline!i32asEquals!.



\subsubsection{Spec Closure Encoding}

In \autoref{sec:pipeline} we already saw how our specification attributes
on functions are desugared by the procedural macro of
\passthrough{\lstinline!libstainless!} into an annotated closure nested
inside the function (\autoref{lst:example2}). The extraction phase
recognises the closures by their attribute and translates them to
Scala's \passthrough{\lstinline!require!},
\passthrough{\lstinline!ensures!} and
\passthrough{\lstinline!decreases!}. Stainless later checks on its own
that the specification does not have any effects.

The encoding with closures is the third spec encoding that we explored
and implemented. It unifies the advantages of the two previous designs
in that it works for \emph{all} kinds of functions, top-level,
implementation methods and abstract or default trait methods, and that
it can use type parameters of the original function. The first encoding
desugared closures to inner functions in the original one. This served
mainly to circumvent the borrow checker. The nested functions duplicated
the parameters of their parent. In that way, new bindings were created
without borrow interference with the actual parameters but with the same
types and identifiers -- simple to extract to
\passthrough{\lstinline!require!} and
\passthrough{\lstinline!ensuring!}. The problem with that encoding was
that it was neither able to use type parameters of the surrounding
function, nor could it use the \passthrough{\lstinline!self!} parameter
inside methods because neither are available to inner functions in Rust.
Therefore, the second encoding was created only for methods in
\passthrough{\lstinline!impl!} blocks. There, specs were desugared to
sibling functions with a special name such that they could declare the
\passthrough{\lstinline!self!} parameter. However, there were now two
different encodings in use simultaneously and even the sibling functions
fell short of accounting for spec attributes on methods in traits.

To support specs on trait implementation methods, we needed to come back
to a nested encoding because Rust does not allow additional items other
than the specified methods in trait implementations. Nested closures
would enable such an encoding and even allow to use surrounding type
parameters at the cost of not being able to use the
\passthrough{\lstinline!self!} parameter. Therefore, our encoding
replaces \passthrough{\lstinline!self!} with a
\passthrough{\lstinline!\_self: Self!} parameter on the closure which
extraction will again correlate with the correct receiver.

The last problem was that abstract trait methods do not have a body for
adding a closure. A simple solution is to add a body with the spec
closure and a panic to the method. Yet, that makes the method a default
method which prevents the compiler of enforcing its implementation by
all implementors -- something we did not want to sacrifice. We achieve
the best of both worlds with conditional compilation. The spec closures
are desugared with a \passthrough{\lstinline!cfg(stainless)!} attribute
that makes them vanish on normal compilation, hence the compiler
enforces implementation, but keeps them when the compiler is run with
the \passthrough{\lstinline!stainless!} flag which happens at
verification.



\section{Limitations}
\label{impl-limitations}

\subsection{Unsupported Rust Features}

In general, language features not mentioned in \autoref{sec:supported-features}
are not yet supported. However, there are mainly two features that are still
mandatory to reach the goal of verifying \emph{idiomatic Rust} -- closures and
sequences.  Other missing features provide less value and prevent the programmer
less from writing normal code, for example, \emph{unsafe Rust} is not supported.
This is a conscious decision as many translations rely on the assumption that
only \emph{safe} Rust is used. User-annotated reference lifetimes are another
example. Although, the borrow checking assumption of the translation enables it
to ignore the exact lifetimes, the tool currently does not extract explicit
lifetimes. Further missing but less complex to add features are supertraits,
i.e. type class inheritance in Scala, top-level constants, and invariants on
ADTs like Stainless knows them.

For closures, most of the infrastructure is already in place as closures are
represented like functions in the compiler. There are some difficulties
nonetheless. Closures can capture variables from the surrounding scope, which
includes moving variables from the surrounding scope into the closure. This
becomes very difficult to manage for Stainless if these variables are mutable
\cite[section 3.4.3]{regb}. The second problem arises with higher-order
functions that take closures as parameters. In Rust, the function parameter type
of a closure must be a type parameter with a trait bound like
\passthrough{\lstinline!F: Fn(i32) -> i32!} becuase the exact shape of the
closure is not clear in advance. This polymorphism is harder to translate than
directly specified lambda types in Scala \passthrough{\lstinline!Int => Int!}.

By sequences I mean vectors, arrays, iterators, but also loops. Implementing
loops and even arrays should be feasible as these are already supported in
Stainless \cite[section ``Imperative'']{stainless-doc}. On the other hand,
iterators and vectors are very difficult to translate because they are not
inherent \emph{language} features but rather some of the most important but also
complex items of the standard library.


\paragraph{One Crate Limitation}

For standard library items we run into the limitation that is imposed by the
one-crate-a-time compilation model of \passthrough{\lstinline!rustc!}. Our tool
is currently not able to extract the code of standard library items because they
are not part of the user crate, hence no HIR is available. This is probably the
biggest technical limitation of Rust-Stainless's implementation. Various
approaches could be explored to solve it:

\begin{itemize}
\item
  If Rust-Stainless could read its serialised output and work with that,
  then the tool could translate a crate, serialise the representation
  and read it again when working on the next crate. For example, one
  could extract and translate the required crate from the standard
  library, serialise it and then import in when translating the user
  crate.

  The problem of that approach is that many of the widely used standard
  library items like vectors are implemented with very advanced features
  and \emph{unsafe Rust.} Extracting code of that level of complexity is
  clearly out of scope for a user-focused tool.
\item
  The contrary approach would be to provide completely synthetic
  definitions of standard items. That is, the tool would detect usage of
  items like a vector and then synthesise some definition and
  implementation like it does for the Stainless set and map.

  While this approach would be technically feasible with the current
  state of the software, it would be an unstable and labour-intensive
  endeavour because the synthetic shadow implementation would need to
  stay in sync with the standard library. Moreover, the standard library
  of Rust is large and the choice of what to provide would be difficult.
\item
  The most promising way of dealing with crate-external items is to let
  the user provide contracts to emulate the external items. Indeed, this
  is the approach other tools take \cite{prusti, mirai}. The given
  contracts will be interpreted as correct and used to verify the user
  code. Our library could also provide contracts for the most frequently
  used standard items, which is what \cite{mirai} does. Keeping such
  contracts up-to-date would still require less work than providing
  synthetic shadow implementations. The only disadvantage of this
  approach is that the user can still state false contracts for the
  external items, which leads to incorrect results.
\end{itemize}

\subsection{Stainless Backend Limitations}

\subsubsection{Type Classes}

Traits are omnipresent in Rust. For example, Rust does not have an
equality operation on all types by default like Scala. Rather,
comparison operators (in the language) are only defined on primitive
types and for other types, the \passthrough{\lstinline!==!} operator is
desugared to a call to the trait method
\passthrough{\lstinline!PartialEq::eq!} of the standard library. Most
types however provide a derived implementation of
\passthrough{\lstinline!PartialEq!} that performs structural comparison.

On one hand, this shows how important our translation of traits to type
classes is. On the other hand, this poses a problem for Stainless
because there, Scala-like structural equality exists on all types. To
deal with the trait methods, the frontend needs to extract the trait
implementations of \passthrough{\lstinline!PartialEq!} with its type
class mechanism. This either forces the user to provide an
implementation for equality that Stainless can understand, or it
requires the solution of the crate-external items problem, as discussed
in the previous section.

The second problem with type classes is that they are expensive in verification
with the current Stainless pipeline. Functions that rely on type class instances
are transformed by multiple phases of the Stainless pipeline, especially the
\emph{refinement lifting}, in such a way that verification may become
untraceable in extreme cases.

A radical solution to the problem is to erase and replace calls to
\passthrough{\lstinline!PartialEq::eq!} by \passthrough{\lstinline!==!}
in the translation. With a similar safety check and argument as for the
erasure of \passthrough{\lstinline!Clone!} to
\passthrough{\lstinline!freshCopy!}, we can argue that only derived
instances of \passthrough{\lstinline!PartialEq!} can be safely replaced
by the structural \passthrough{\lstinline!==!} operator of Scala.

\subsubsection{Mutability}

As \autoref{sec:aliasing-restrictions} described, the general translation can be
tailored around the specific aliasing restrictions of the Stainless backend.
This is by itself a limitation; if we had a Scala verifier for the entire Scala
language we could simply use the general translation. Nonetheless, thanks to
Rust's borrow checking guarantees, the translation can be adapted rather well to
the restrictions but some limitations remain, as \autoref{trans-limitations}
discusses.

From an implementation point of view, the \emph{imperative phase} of Stainless
is not the most stable part of the pipeline and is also still under active
development. Rust-Stainless targets that phase as a new frontend in ways that
were unforeseen and thus found many bugs in the process. Most of the bugs have
already been solved, for example an incorrect constant
propagation.\footnote{\url{https://github.com/epfl-lara/stainless/issues/1090}}
However, for code using mutability in complex ways it is still possible to find
new bugs in the backend.

As discussed in the previous section, refinement lifting makes examples using
type classes more expensive to verify. In combination with the mutable cell
encoding and recursive types like the linked-list, this unfortunately leads two
larger benchmarks of the test suite to time
out.\footnote{\url{https://github.com/epfl-lara/stainless/issues/1093}} Luckily,
the refinement lifting phase is set to be removed from the pipeline in the
future which may solve these issues.

\paragraph{Other Approaches}

To overcome the limitations of Stainless's current imperative phase, a
new \emph{full imperative} phase using a \emph{heap encoding} has been
proposed \cite{new-imperative}. That new phase has explicit support for
mutable references \passthrough{\lstinline!AnyHeapRef!} which represent
parts of the heap. Furthermore, it uses annotations on functions that
state which references are read (\passthrough{\lstinline!reads!}) and
which are written to (\passthrough{\lstinline!modifies!}) by the
function. These two features are very promising to target from
Rust-Stainless because they resemble things that are already in our
mutability translation. The mutable references are very close to our
mutable cells and it might even be possible to infer the information
needed for the read and write annotations from the mutability of the
function parameters, which is explicitly stated in Rust.

A radically different approach for dealing with mutability would be to
extract the Rust program not from the THIR but from the lower-level MIR.
We discuss this approach in the next section.

\subsection{Design Limitations}
\label{mir-thir}

The current way of translating the THIR to Stainless ASTs has many
advantages. The THIR is very close to Stainless ASTs and errors,
counter-examples or insights coming from Stainless are easily mapped
back and forth between the two representations. On the downside, the
THIR still has many features that all need to be understood by our
translation, which can render the latter more complex. More importantly,
the THIR does not have any information about liveness, reference
lifetimes, and borrowing because all these analyses are only performed
later on the MIR. This is the fundamental limitation of translating from
the THIR.

The advantage of the MIR is that the representation is even more
explicit, there are less features to translate, and lifetimes have been
resolved. That means, it would be possible to manually propagate changes
back to borrowed variables at the lifetime end of mutable borrows. On
the other hand, the MIR is in CFG form and it should be challenging to
transform that graph form back to a syntax tree. It is also unfeasible
to combine the THIR and the MIR because they do not use the same
identifiers for variables.
