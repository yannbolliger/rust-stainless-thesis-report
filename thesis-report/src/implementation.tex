Rust-Stainless is developed as an open source software
project.\footnote{\url{https://github.com/epfl-lara/rust-stainless/}} It was
created by Georg Schmid to explore a new frontend to Stainless for the Rust
language. Upon completion of this thesis project, the tool is implemented in
approximately 12K lines of Rust code. Most features described here are available
on the \lstinline!master! branch, except for the mutability translation that
lives on the \lstinline!mutable-cells!
branch.\footnote{\url{https://github.com/epfl-lara/rust-stainless/pull/164}}

Before presenting the tool's design and implementation details, the next section
provides some background on the Rust compiler needed to understand the inner
workings of the tool. The subsequent sections distinguish between language
features the tool was already capable of extracting before this project and new
features that have been introduced. The final section discusses limitations of
the current implementation.


\section{Background}

\subsection{Rust Compiler}

To translate Rust without doing too much busy-work, Rust-Stainless leverages the
heavy lifting done by the Rust compiler \cite{rustc-guide}, \lstinline!rustc!.
The compiler takes Rust source code as input and produces an executable binary.
This process involves multiple phases that each transform or \emph{lower} the
higher-level input source into a lower-level representation. The following
paragraphs give a brief overview of the compilation process and the leftmost
column of \autoref{fig:flowchart} illustrates the different phases.

The Rust compiler always operates on a single crate. That is, each crate is
compiled separately and only afterwards linked to potential other crates. This
means that the \emph{intermediate representations} described hereafter are only
available for items of the currently compiled crate with some exceptions for
metadata of public items, like function signatures that need to be accessible
across crates.

The first two compilation phases are concerned with transforming the input text
into a token stream -- lexing -- and then into an \emph{abstract syntax tree
(AST)} -- parsing. First syntactical validations, name resolutions and macro
expansion are performed on the AST. While the AST is already a representation of
the program, it still maps directly to the source code and can be seen as a data
structure representation of the source text.

The first intermediate representation (IR) constructed from the AST is the
\emph{high-level IR (HIR)}. It contains much less high-level features than
surface Rust, because many have been desugared. The HIR is used to type check
the program. In that process an even lower-level IR is created, the \emph{typed
HIR (THIR)}. Still in the form of a syntax tree, the THIR contains fully
explicit type information.

The THIR is used to construct the \emph{mid-level IR (MIR)} that has the form of
a \emph{control-flow graph (CFG)}. Such a graph is a diagram that consists of
\emph{basic blocks} of code and arrows between them that represent all the
possible paths the control flow can take. The MIR still has generic types but
because it is a CFG it is much more convenient for processes like liveness
analysis, optimisations, and most importantly, the borrow check of the program.

The last compilation phase is \emph{code generation}. The generic code is
\emph{monomorphised} i.e.~copied and specialised for each type it is
instantiated with. Then, a special IR for the \emph{LLVM} framework \cite{llvm}
is generated. LLVM is a general purpose compiler backend, also used by C++. It
will perform much more performance optimisations and finally generate the
assembly code.

\section{System Overview}

\subsection{Design}

Our tool consists of multiple components, most of which are implemented as their
own crate. Each component modularly fulfils a step in the overarching goal of
translating Rust for Stainless.

Rust-Stainless has itself a frontend and a backend.
\lstinline!stainless_frontend! is the frontend crate and contains two
executables that start the tool and deal with command line arguments. The
subcommand for the Cargo build tool \passthrough{\lstinline!cargo stainless!} is
the most common way of running Rust-Stainless. Internally, it calls the second
stand-alone binary \lstinline!rustc_to_stainless! which runs the actual
frontend.

\begin{figure}
  \begin{center}
  \input{img/flowchart}
  \caption{
    The Rust-Stainless pipeline depicted with all intermediate representations
    of the user program. The left column on its own shows the normal compilation
    pipeline of Rust's compiler. The grey parts are not executed in Rust-Stainless.
  }
  \label{fig:flowchart}
  \end{center}
\end{figure}

The programmer also sees another interface of Rust-Stainless, its library
\lstinline!libstainless!. The library needs to be imported as
\passthrough{\lstinline!extern crate stainless;!} in all code to be verified. It
provides the user-facing parts of Rust-Stainless like the specification macros
and some built-in Stainless types useful for specification.

The principal translation is performed by the \lstinline!stainless_extraction!
crate. The frontend calls the method \lstinline!extract_crate! which retrieves
the HIR from the compiler and translates it to Stainless AST with the help of
another crate, \lstinline!stainless_data!. The latter contains auto-generated
Rust definitions of the Stainless AST types as well as code to serialise them.

Finally, \lstinline!stainless_backend! is responsible for spawning and
interacting with a JVM subprocess of the Stainless executable. The executable
consist of the normal Stainless verification pipeline but with a custom
entry-point called \lstinline!Noxt-Frontend!. ``Noxt'' stands for \emph{no
extraction} which means it takes as input serialised trees instead of extracting
trees from the Scala compiler.

\subsection{Pipeline}
\label{sec:pipeline}

Having introduced the system's components, the next section traces the path of
an exemplary program through the pipeline in more detail. The path can also be
followed on \autoref{fig:flowchart}. Gaining insight into the pipeline will
increase understanding of the design choices made.

In \autoref{lst:example}, the Stainless library is imported such that the
post-condition specification attribute \lstinline!#[post(...)]! is available.
The attribute is implemented as a procedural macro\footnote{Procedural macros
invoke user-provided code at compilation-time and thus allow for more complex
transformations of the AST inside a macro \cite[section ``Procedural
Macros'']{rustref}.} and will be expanded to a closure inside the function
(\autoref{lst:example2}).

\noindent\begin{minipage}[b]{.45\textwidth}
\begin{lstlisting}[
  language=Rust,
  caption={Rust program with a post-condition.},
  label={lst:example},
]
extern crate stainless;
use stainless::*;

struct A(i32);

#[post(ret.0 >= 0)]
fn f(a: A) -> A {
  A(a.0 * a.0)
}
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}[b]{.52\textwidth}
\begin{lstlisting}[
  language=Rust,
  caption={Desugared post-condition.},
  label={lst:example2}
]
fn f(a: A) -> A {
  #[clippy::stainless::post]
  |a: A, ret: A| -> bool {ret.0 >= 0};
  A(a.0 * a.0)
}
\end{lstlisting}
\end{minipage}

The \lstinline!stainless_frontend! invokes the compiler via the
\lstinline!rustc_driver! library and lets it run until all analyses are complete
and pass, otherwise the tool fails with the error returned by \lstinline!rustc!.
In particular, the compiler does the lexing, parsing, macro expansion and IR
construction. Secondly, the compiler type and borrow checks the program. This is
how the strong assumption from \autoref{correctness-claim} is achieved. Once
analysis is complete, the extraction module is invoked on the HIR. As the HIR is
only ever constructed for the current crate, Rust-Stainless also only translates
the current crate. That limitation of our tool is discussed in
\autoref{impl-limitations}.

The extraction traverses all the \emph{items} of the crate, that is, top-level
functions, structs, enums, \lstinline!impl! blocks and their methods, as well as
traits. It directly constructs Stainless definitions for ADTs. For function
bodies, the extraction uses the THIR, which is guaranteed to exist as the type
check passed. For illustration, \autoref{apx:thir-example} shows the THIR for
the body of the function in \autoref{lst:example}.

If all the THIR can be translated to Stainless AST without errors, i.e.~there
are no unsupported features in the program, the AST is serialised to a custom
binary format understood by Stainless. At this point, the program is represented
by a list of functions, a list of ADTs and a list of classes
(\autoref{lst:stainless-trees}).

\begin{lstlisting}[
  language=Scala,
  label={lst:stainless-trees},
  caption={Extracted Stainless ADTs and functions, printed as code.}
]
sealed case class A(_0: MutCell[Int])
sealed case class MutCell[T @mutable]((value: T @mutable) @var)

@pure
def f(a: A): A = {
  freshCopy(A(MutCell[Int](a._0.value * a._0.value)))
} ensuring {
  (ret: A) => ret._0.value >= 0
}
\end{lstlisting}

If the user specified to export the AST, the binary format is simply written to
a file. Otherwise, Rust-Stainless spawns a subprocess with the
\lstinline!Noxt-Frontend! of Stainless and communicates with it via standard
input and output. The subprocess reads the AST from a temporary file, performs
some minor transformations and passes it to the verification pipeline. In the
end, it reports back the results in JSON format such that Rust-Stainless can
print them. In the case of the example, Stainless returns a problem: the
multiplication on line 6 of \autoref{lst:stainless-trees} could overflow and
therefore, the post-condition does not hold.



\section{Extraction}

\subsection{Supported Rust Features}
\label{sec:supported-features}

\begin{lstlisting}[
  float,
  language=Rust,
  label={lst:existing},
  caption={Example of existing features in Rust-Stainless.}
]
pub fn i32_ops(x: i32, y: i32) {
  assert!(x + y == 2 * x);
  if x >= 0 && x < 1<<30 {
    assert!(x == (x + x) / 2);
  }
}
enum Maybe<T> {
  Nothing,
  Just { value: T }
}
fn get_or<T>(maybe: Maybe<T>, default: T) -> T {
  match maybe {
    Maybe::Nothing => default,
    Maybe::Just { value } => value,
  }
}
#[pre(x >= 0)]
#[pre(x < 10)]
#[post(ret >= 0)]
pub fn fact(x: i32) -> i32 {
  if x <= 0 { 1 }
  else { fact(x - 1) * x }
}
\end{lstlisting}

\subsubsection{Existing Features}

The initial fragment of the Rust language that the tool could extract and
translate underlay strict restrictions: all code needed to be functional,
immutable and the only allowed side-effect was \lstinline"panic!". References,
heap allocation and with it recursive data types were impossible.

Apart from that, a large part of the language was already supported, i.e.~most
of the control-flow syntax, top-level functions with bodies, integer and boolean
expressions, string literals, pattern matching, ADTs, including tuples (without
their pattern matching), and generics. Function specifications (specs), that is
pre- and postconditions, could be stated with the \lstinline!pre! and
\lstinline!post! attributes from the \lstinline!stainless! crate.

The argument of a spec is a regular Rust expression that must have no effect on
any variables of the function body. This posed a problem in the absence of
references because oftentimes, the expression would consume a function parameter
of moveable type multiple times which does not borrow check. As a work-around,
one could add multiple specs of the same kind to a function, which is equivalent
to multiple \lstinline!&&!-concatenated expressions. With all of the above, an
example of supported and verified Rust code before this thesis project is
\autoref{lst:existing}.

\subsubsection{New Features}

This section gives an overview of all the language features that were added to
the extraction in the course of this project except for the mutability
translation which has been introduced in \autoref{translation}. The features
described here are available on the \lstinline!master! branch of the project.

\paragraph{Syntactical and Notational Improvements}

Support was added for:

\begin{itemize}
\item
  \passthrough{\lstinline!else if!} expressions,
\item
  \passthrough{\lstinline!let!} bindings with user-specified type
  annotation, \passthrough{\lstinline!let t: u16 = 1;!},
\item
  pattern matching on tuples,
\item
  accessing tuple struct fields by their numerical identifier,
  \passthrough{\lstinline!A(2, 3).0!},
\item
  the \passthrough{\lstinline!return!} keyword at most points
  of a function (but not in \lstinline!if! conditions and guards),
\item
  \passthrough{\lstinline!usize!} and \passthrough{\lstinline!isize!}
  integer types that have the bit-length of a pointer on the targeted
  platform,
\item
  \emph{struct update syntax}, a short-hand notation for creating a
  struct from an existing one,
\begin{lstlisting}[language=Rust]
struct A { a: i32, b: bool, c: char }
let x: A = A { a: 123, b: true, c: 'c' };
let y: A = A { b: false, ..x }; // copies `x.b`, `x.c`
\end{lstlisting}

\item
  crate local modules and imports, which includes the ability of
  splitting up a crate into multiple files, and finally,
\item
  panics in expression locations like an arm of a pattern match.
\begin{lstlisting}[language=Rust]
match Option::Some(123) {
  Option::Some(x) => x,
  Option::None => panic!("no value"),
}
\end{lstlisting}

\end{itemize}

\paragraph{Immutable References and Heap Allocation}

It is now possible to immutably borrow places, pass immutable references as
values and allocate data on the heap with boxes. Although already presented in
\autoref{translation}, the feature is mentioned here because it exists
independently of the mutability translation.

The above enables recursive data types like the typical, functional linked-list.
Additionally, this eases the problem of borrow checking spec expressions because
expressions that only read data, like most specifications do, can now take a
reference instead of consuming the data.

\begin{lstlisting}[language=Rust, style=short]
pub enum List<T> {
  Nil,
  Cons(T, Box<List<T>>),
}
\end{lstlisting}

\paragraph{Measure Attribute}

Recursive proofs in Stainless often require the programmer to state the
induction variable with a \lstinline!decreases! call in Scala. This helps
Stainless infer the so called \emph{measure} of the proof, with which it checks
termination. The same feature was introduced in Rust as a new spec attribute
which enables verification of recursive functions, like \autoref{lst:measure}.

\begin{lstlisting}[
  language=Rust,
  caption={Measure attribute.},
  label={lst:measure}
]
#[measure(l)]
fn size<T>(l: &List<T>) -> u32 {
  match l {
    List::Nil => 0,
    List::Cons(_, tail) => 1 + size(tail),
  }
}
\end{lstlisting}

\paragraph{Stainless Library}

The \lstinline!stainless! crate is exposed to the programmer and contains
helpers for specifying proofs and conditions. This is the equivalent of the
\lstinline!stainless! package in Scala. In addition to the pre-, post- and
measure attributes \lstinline!libstainless! now offers an immutable, infinite
set \passthrough{\lstinline!stainless::Set<T>!} and map
\passthrough{\lstinline!stainless::Map<K, V>!} implementation, see
\autoref{lst:map-set}.

In extraction, both of these types are translated to Stainless's built-in
infinite set and map type. Hence, they are backed and well-understood by
Stainless which enables their proof utility. At runtime, the collections are
backed by a runnable implementation that relies on the
\lstinline!im!\footnote{\url{https://docs.rs/im/15.0.0/im/}} crate. The Rust
interface of the collections was designed so as to resemble the
\lstinline!std::collections::HashSet! and \lstinline!HashMap! as closely as
possible.

\begin{lstlisting}[
  float,
  language=Rust,
  caption={The interface of the Stainless collections in Rust.},
  label=lst:map-set
]
Set<T> {
  fn new() -> Self;
  fn singleton(t: T) -> Self;
  fn insert(&self, t: T) -> Self;
  fn contains(&self, t: &T) -> bool;
  fn union(self, other: Set<T>) -> Self;
  fn intersection(self, other: Set<T>) -> Self;
  fn difference(self, other: Set<T>) -> Self;
  fn is_subset(&self, other: &Set<T>) -> bool;
}
Map<K, V> {
  fn new() -> Self;
  fn get(&self, key: &K) -> Option<&V>;
  fn get_or<'a>(&'a self, key: &K, elze: &'a V);
  /// Panics if the key is not in the map.
  fn index(&self, key: &K) -> &V;
  fn contains_key(&self, key: &K) -> bool;
  fn insert(&self, key: K, val: V) -> Self;
  fn remove(&self, key: &K) -> Self;
}
\end{lstlisting}

Furthermore, the library provides a helper function
\passthrough{\lstinline!implies!} that let's one write the logical
implication $p \implies q \equiv \neg{p} \land q$ over boolean expressions.


\paragraph{External and Synthesised ADTs}

Internally, the \lstinline!Map<K, V>! of the Stainless crate relies on the
\lstinline!MutableMap! of Scala Stainless with values of type
\lstinline!Option[V]!. To perform that translation, the extraction needs to
create trees of the \lstinline!Option! type, even if the
\lstinline!std::option::Option! doesn't occur in the program. Therefore,
Rust-Stainless can now synthesise values and types for certain specific ADTs:
\lstinline!Option!, tuples and mutable cells as described in
\autoref{sec:translation}.

The frontend also supports extraction of crate-external ADTs like
\lstinline!std::result::Result!. That means, the programmer can use the standard
structures and they are correctly translated, provided that no methods of these
types are used. This is the one-crate-limitation, discussed in
\autoref{impl-limitations}.

\paragraph{Implementation Blocks, Traits and Laws}

The largest addition, other than mutability, of this project is support for
implementation blocks, methods, and traits with contracts, as introduced in
\autoref{laws-intro}. This includes solving some intricate problems. For
example, the Rust compiler automatically and implicitly resolves which trait
implementation to use for any given trait method call. If no suitable
implementation is in scope, it signals an error.  A similar mechanism can be
achieved in Scala by means of \emph{type classes}. The resolution of type class
methods and instances is done through the \emph{implicits mechanism} of regular
Scala. In Stainless however, this resolution has to be done manually. Therefore,
Rust-Stainless not only extracts type classes from Rust traits, but it also
infers which type class instance to call at each method call site.

Furthermore, our tool is capable of extracting laws and specifications of traits
and their implementations, including specification attributes on abstract
methods. Lastly, it can extract  trait bounds like \passthrough{\lstinline!T:
Equals!} from top-level functions and implementation blocks, and transform them
to the equivalent Scala pattern of \emph{evidence parameters}. More details on
that tranlsation follow in the next section.



\subsection{Implementation Details}

\subsubsection{Extraction Overview}
\label{sec:extraction-overview}

As seen in \autoref{sec:pipeline}, the majority of the work of Rust-Stainless
happens in the extraction of the HIR to Stainless AST. This subsection takes a
more detailed look at the most interesting phase of our tool, implemented in the
\lstinline!stainless_extraction! crate.

Before dealing with user code, the extraction needs to register some specially
treated items, called \emph{standard items}. These are Rust language features
like panic, standard library items like \lstinline!Box<T>! and
\lstinline!Option<T>!, but also all items of \lstinline!libstainless! like
\lstinline!Set<T>! and \lstinline!implies!. Extraction needs to know the
identifiers (the \lstinline!DefId!s) of those items in order to recognise them
in user code and trigger their specialised treatment. Initially, only the
\emph{definition paths} of the items to detect are known, e.g.
\lstinline!stainless::Set::<T>::new!, but that does not suffice because
\lstinline!rustc! does not have an API to query items from other crates \emph{by
path} at the time of writing. All the lookups are done by \lstinline!DefId!.
Therefore, the implementation has to enumerate all \lstinline!DefId!s from the
\lstinline!std! and \lstinline!stainless! crate, compare them by name to the
desired items and register them if needed. This approach is clearly a
brute-force work-around to the lack of by-path lookups in \lstinline!rustc!, but
as the number of crates to take into consideration is fixed and low, the lookup
time is constant still relatively low (cf. \autoref{evaluation}).

After standard item detection the tool can turn to user code. The main procedure
of the extraction enumerates all top-level
items\footnote{\url{https://doc.rust-lang.org/nightly/nightly-rustc/rustc_hir/hir/enum.ItemKind.html}}
of the crate. For enums and structs, the phase directly proceeds and translates
the HIR definition to a Stainless ADT definition. Because enumeration order is
undefined, all the top-level methods of the extraction follow the same idea:
\lstinline!get_or_extract!. That is, the first time an item is visited, it is
extracted and its definition is stored in state, then on subsequent encounters
the definition is simply retrieved.

For functions, the extraction distinguishes between external, abstract, and
local functions, but not between methods and functions because in the HIR the
two are the same (with the first parameter of methods being the receiver).
External and abstract functions are only extracted from the HIR as they only
have a signature. For local functions, the body expression is queried from the
THIR and extracted by the \lstinline!expr! module which takes a
\lstinline!thir::Expr! and returns a \lstinline!st::Expr!, i.e. it contains all
the translation details.

\subsubsection{Synthesis}

Multiple translations in Rust-Stainless rely on the ability to synthesise
expressions of certain ADT types that do not necessarily occur in user code. For
example for the Stainless map the translation needs to construct options
(\passthrough{\lstinline!Some(v)!}), in other locations it creates tuples,
e.g.~\passthrough{\lstinline!Tuple3(x, y, z)!}. Moreover, the fields of these
ADTs also need to be available: \lstinline!tuple.\_0!.

The synthesis module benefits from the \lstinline!get_or_extract! pattern. For
example, when a translation needs the option type, it triggers its synthesis.
But all synthesis methods internally implement a \lstinline!get_or_create!
logic, i.e.~if the option type has already been either extracted from user code
or synthesised by a former synthesis call, it is simply reused and the demanded
ADT expression can be built with the existing definition. That way, ADTs are
only synthesised on demand and there is no risk of synthesising a definition
that has already been extracted.

\subsubsection{Trait to Type Class Translation}
\label{type-class-extraction}

Rust-Stainless extracts traits and models them as type classes in Scala. This
introduces a distinction between regular \lstinline!impl! blocks for which it
suffices to extract the methods as top-level functions, and
\passthrough{\lstinline!impl TraitX for TypeA!} blocks that need to be extracted
as type class implementations, i.e.~\emph{case classes} or \emph{case objects}.
Traits themselves are extracted as \emph{abstract classes}, see
\autoref{lst:clstranslation0}.

Internally, Rust represents \passthrough{\lstinline!impl TraitX for TypeA!}
blocks with a \emph{trait bound} on the block i.e.~\passthrough{\lstinline!Self:
TraitX!}, while Scala uses inheritance (\passthrough{\lstinline!extends!}).
Furthermore, Rust traits are implemented on the implicit \lstinline!Self! type
parameter, whereas Scala type classes always have at least one type parameter
representing the type for which the class is implemented. Fortunately, the Rust
compiler internally treats the \lstinline!Self! like a regular type parameter,
hence internally it is already in the Scala form.

\begin{figure}
\begin{minipage}[t]{.49\textwidth}
\begin{lstlisting}[
  language=Rust,
  showlines=true,
  caption={Examples of traits and implementations with and without trait bounds.},
  label={lst:clstranslation0}
]
trait Equals {
  fn equals(&self, x: &Self) -> bool;

  fn not_equals(&self, x: &Self)
    -> bool {
      !self.equals(x)
    }
}
trait Other<X, Y> { ... }

impl Equals for i32 { ... }


impl<T: Equals> Equals for List<T>
  { ... }

let list: List<i32> = List::Cons(
  123, Box::new(List::Nil)
);
list.equals(&List::Nil)
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}[t]{.49\textwidth}
\begin{lstlisting}[
  language=Scala,
  caption={
    Translation as type classes (\lstinline!abstract!) and implementations.
    Trait bounds are translated as evidence parameters.},
  label={lst:clstranslation}
]
abstract class Equals[Self] {
  def equals(self: T, x: T): Boolean

  def notEquals(
    self: T, x: T
  ): Boolean =
    !this.equals(x, y)
}
abstract class Other[Self, X, Y]
  { ... }
case object i32asEquals
  extends Equals[Int] { ... }

case class ListasEquals[T](
  ev0: Equals[T]
) extends Equals[List[T]] { ... }

val list = Cons(123, Nil())
ListasEquals[i32](i32asEquals)
  .equals(list, Nil())
\end{lstlisting}
\end{minipage}
\end{figure}

As \autoref{lst:clstranslation} shows, the trait bounds on type parameters are
converted to evidence parameters in Scala, like \passthrough{\lstinline!ev0:
Equals[T]!}. Evidence parameters force the caller to prove that the instantiated
type satisfies the bound by providing an instance of the corresponding type
class. This is equivalent to Rust's compiler ensuring that
\passthrough{\lstinline!impl Equals for T!} is in scope. If an implementation
has no type parameter, it can be extracted as a ground case object.

If there are classes, it is also necessary to distinguish \emph{function calls}
from \emph{method calls}. This distinction is mostly achieved by adding flags
like \passthrough{\lstinline!abstract!} and
\passthrough{\lstinline!methodOf(i32asEquals)!} to methods. The challenge of
method calls is to resolve the receiver instance they are called on. For
example, \autoref{lst:clstranslation} shows a call to \lstinline!this.equals!
inside the type class. In Rust, the call is on the first parameter of the
function which is also the receiver. This is implicitly resolved by the
compiler. In Stainless however, the call needs to happen on the type class
instance and because our type class instances are only created in the
extraction, the tool also has to resolve the receivers itself.

Instance resolution takes a triple of type class identifier, receiver type and
type parameters, as well as the current surrounding class to resolve the
receiver instance. For example, inside a type class, the \lstinline!this!
instance is accessible, inside classes with evidence parameters, the evidence
instances are available (e.g. \lstinline!ev0.eq(x, y)! in
\lstinline!ListasEquals[T]!) and ground case objects are always in scope. As a
last resort, instance resolution recursively checks whether it can create a new
type class instance by providing it the required evidence arguments. This
happens for example for the call on line 20 of \autoref{lst:clstranslation0}. It
gets translated to a new instance of \lstinline!ListasEquals! that is created
with the ground object \lstinline!i32asEquals!.



\subsubsection{Spec Closure Encoding}

Subsection \ref{sec:pipeline} already highlighted how specification attributes
on functions are desugared by the procedural macro of \lstinline!libstainless!
into an annotated closure nested inside the function (\autoref{lst:example2}).
The extraction recognises the closures by their annotation and translates them
to Scala's \lstinline!require!, \passthrough{\lstinline!ensures!} and
\passthrough{\lstinline!decreases!}. Stainless later checks on its own that the
specifications do not have any effects.

The encoding with nested closures is the third spec encoding that I explored and
implemented. It unifies the advantages of the two previous designs: it works for
\emph{all} kinds of functions, be they top-level, implementation methods, and
abstract or default trait methods; and it can use type parameters of the
original function.

The first encoding desugared closures to nested functions in the original
function. This served mainly to circumvent the borrow checker. The nested
functions duplicated the parameters of their parent. In that way, new bindings
were created without borrow interference with the actual parameters but with the
same types and identifiers. The problem was that this encoding was neither able
to use type parameters of the surrounding function, nor could it use the
\passthrough{\lstinline!self!} parameter of methods because neither are
available to inner functions in Rust.

Therefore, the second encoding was created only for methods in \lstinline!impl!
blocks. There, specs were desugared to sibling functions with a special name
such that they could declare a \lstinline!self! parameter. However, there were
now two different encodings in use simultaneously and even the sibling functions
couldn't provide spec attributes on trait methods.

Rust does not allow additional items other than the specified methods in trait
implementations. To support specs on trait methods, the third encoding therefore
uses nested closures. They can even use surrounding type parameters, at the cost
of not being able to use the \lstinline!self! parameter. To solve that, the
encoding replaces \lstinline!self! with a \passthrough{\lstinline!\_self: Self!}
parameter on the closure. Later, extraction will again correlate this parameter
with the correct receiver.

Finally, abstract trait methods do not have a body in which one can nest a
closure. A simple solution is to add a body with the spec closure and an
\lstinline"unimplemented!" panic. Yet, that makes the method a default method
which prevents the compiler from enforcing its implementation by all
implementors. That  was too much of a sacrifice and the solution was to use
conditional compilation. The spec closures are desugared with a
\lstinline!#[cfg(stainless)]! attribute that makes them vanish in normal
compilation, hence, the compiler enforces implementation, but keeps them when
the compiler is run with the \lstinline!stainless! flag which happens at
verification.



\section{Limitations}
\label{impl-limitations}

\subsection{Unsupported Rust Features}

In general, language features not mentioned in \autoref{sec:supported-features}
are not yet supported. However, there are mainly two features that are still
mandatory to reach the goal of verifying \emph{idiomatic Rust}: closures and
sequences. Other missing features provide prevent the programmer less from
writing normal code, for example, \emph{unsafe Rust} is not supported. This is a
conscious decision as many translations rely on the assumption that only
\emph{safe} Rust is used. User-annotated reference lifetimes are another
example. Although, the borrow checking assumption enables the translation to
ignore exact lifetimes, the tool currently does not extract explicit lifetimes.
Further missing but less complex to add features are supertraits, i.e. type
class inheritance in Scala, top-level constants, and invariants on ADTs, known
in Stainless.

For closures, most of the infrastructure is already in place as they are
represented like functions in the compiler. There are some difficulties
nonetheless. Closures can capture variables from the surrounding scope. That
includes moving variables from the surrounding scope into the closure. This
becomes difficult to manage for Stainless if these variables are mutable
\cite[section 3.4.3]{regb}. The second problem arises with higher-order
functions that take closures as parameters. In Rust, the function parameter type
for a closure must be a type parameter with a trait bound like
\passthrough{\lstinline!F: Fn(i32) -> i32!} because the exact shape of the
closure is not clear in advance. This polymorphism is harder to translate than
directly specified lambda types, like in Scala \passthrough{\lstinline!Int =>
Int!}.

By sequences I mean vectors, arrays, iterators, but also loops. Implementing
loops and even arrays should be feasible as these are already supported in
Stainless \cite[section ``Imperative'']{stainless-doc}. On the other hand,
iterators and vectors are very difficult to translate because they are not
inherent \emph{language} features but rather some of the most important but also
complex items of the standard library.


\paragraph{One Crate Limitation}

For standard library items, Rust-Stainless runs into the limitation imposed by
the one-crate-a-time compilation model of \lstinline!rustc!. The tool is
currently not able to extract code of standard library items because they are
not part of the user crate, hence no HIR is available. This is currently the
biggest \emph{engineering limitation} of Rust-Stainless. Various approaches
could be explored to solve it:

\begin{itemize}

\item If Rust-Stainless could read its binary output format and work with that,
the tool could translate a crate, serialise the representation and read it again
when working on the next crate. This way, the relevant items from the standard
library could be extracted and later imported, when translating the user crate.

The problem of that approach is that many of the widely used standard library
items like vectors are implemented with very advanced features like unsafe Rust.
Extracting code that complex is currently out of scope.

\item The contrary approach would be to provide completely synthetic definitions
of standard items. That is, the tool would detect items like vectors and
synthesise some implementation for them, like it does for the Stainless set and
map.

While this approach would be technically feasible, it would be an unstable and
labour-intensive endeavour because the synthetic shadow implementation would
need to stay in sync with the standard library. Moreover, Rust's standard
library is large and it would be difficult to  choose which features to provide.

\item The most promising way of dealing with crate-external items is to extract
contracts for external items that emulate them. Indeed, this is the approach
other tools take \cite{prusti, mirai}. The given contracts will be interpreted
as correct and used to verify the user code. The library could also provide
contracts for the most frequently used standard items, which is what
\cite{mirai} does. Keeping such contracts up-to-date would still require less
work than providing synthetic shadow implementations. The only disadvantage of
this approach is that the user can state false contracts for external items,
leading to incorrect results.

\end{itemize}

\subsection{Stainless Backend Limitations}

\subsubsection{Type Classes}

Traits are omnipresent in Rust. For example, Rust does not have an equality
operation on all types by default like Scala. Rather, comparison operators are
only defined on primitive types in the language and for other types, for example
the \lstinline!==! operator is desugared to a call to the trait method
\lstinline!PartialEq::eq! of the standard library. Most types however provide a
derived implementation of \lstinline!PartialEq! that performs structural
comparison.

On one hand, this shows how important our translation of traits to type classes
is. On the other hand, it poses a problem for Stainless because in Scala
structural equality exists on all types. To deal with trait methods, the
frontend needs to extract the trait implementations of \lstinline!PartialEq!
with its type class mechanism. This either forces the user to provide an
implementation for equality, or it requires the solution of the crate-external
items problem, discussed in the previous section.

The second problem with type classes is that they are expensive in verification
with the current Stainless pipeline. Functions that rely on type class instances
are transformed by multiple phases of the Stainless pipeline, especially the
\emph{refinement lifting}, in such a way that verification may become
untraceable in extreme cases.

A radical solution to the problem would be to erase and replace calls to
\lstinline!PartialEq::eq! by \lstinline!==! in Scala. With a similar safety
check as for the erasure of \lstinline!Clone! to \lstinline!freshCopy!, one can
argue that derived instances of \lstinline!PartialEq! can be safely replaced by
the structural \lstinline!==! operator of Scala.

\subsubsection{Mutability}

As \autoref{sec:aliasing-restrictions} described, the general mutability
translation can be tailored around the specific aliasing restrictions of the
Stainless backend. This is by itself a limitation; if Stainless worked for the
entire language, one could simply use the general translation. Nonetheless,
thanks to the borrow checking guarantees, the translation can be adapted rather
well to the restrictions but some limitations remain, as
\autoref{trans-limitations} discusses.

From an implementation point of view, the imperative phase of Stainless is not
the most stable part of the pipeline and is also still under development.
Rust-Stainless targets that phase as a new frontend in unforeseen ways  and
thereby found multiple bugs. Most of the bugs have already been
solved.\footnote{For example an incorrect constant propagation:
\url{https://github.com/epfl-lara/stainless/issues/1090}.} However, for code
using mutability in complex ways it is still possible to find new bugs in the
backend.

As discussed in the previous section, refinement lifting makes examples using
type classes more expensive to verify. In combination with the mutable cell
encoding and recursive types like the linked-list, this unfortunately leads two
larger benchmarks of the test suite to time
out.\footnote{\url{https://github.com/epfl-lara/stainless/issues/1093}} Luckily,
the refinement lifting phase is set to be removed from the pipeline in the
future which may solve the issue.

\paragraph{Other Approaches}

To overcome the limitations of Stainless's imperative phase, a new \emph{full
imperative} phase using a \emph{heap encoding} has been proposed
\cite{new-imperative}. That phase has explicit support for mutable references,
\lstinline!AnyHeapRef!, which represent parts of the heap. Furthermore, it uses
annotations on functions to state which references are read (\lstinline!reads!)
and which are written to (\lstinline!modifies!) by the function. These two
features are very promising to target from Rust-Stainless because they resemble
things that are already in the mutability translation. \lstinline!AnyHeapRef! is
similar to mutable cells and it might be possible to infer the information
needed for the read and write annotations from the mutability of the function
parameters (which is explicitly stated in Rust).

A radically different approach for dealing with mutability would be to extract
the Rust program not from the THIR but from the lower-level MIR. The next
subsection is dedicated to that discussion.

\subsection{Design Limitations}
\label{mir-thir}

The current approach of using the THIR has many advantages. The THIR is well
suited for translation to Stainless AST because it is still in the form of an
AST but all the type information is explicit and implicit features like method
calls and dereferences have been resolved or desugared. In that sense, the THIR
is the representation closest to Stainless AST and errors, counter-examples, or
insights coming from Stainless are easily mapped back and forth between the two.
On the downside, the THIR still has many features that all need to be understood
by our translation, which becomes more complex. More importantly, the THIR does
not have any information about liveness, reference lifetimes, and borrowing
because all these analyses are only performed later, on the MIR. This is the
fundamental limitation of translating from the THIR.

The advantage of the MIR is that the representation is even more explicit, there
are less features to translate, and lifetimes have been resolved. That means, it
would be possible to manually propagate changes back to borrowed variables at
the lifetime end of mutable borrows. On the other hand, the MIR is in CFG form
and it should be challenging to transform that graph back to a syntax tree for
Stainless AST. It is also nearly impossible to combine the THIR and the MIR
because they do not use the same identifiers for variables.

\hfill \break \noindent With this chapter, the entire Rust-Stainless system has
been introduced and explained. Design choices and accompanying limitations were
discussed in the last section and may be compared to other approaches, listed in
\autoref{related-work}. The next chapter evaluates our tool under different
perspectives.
